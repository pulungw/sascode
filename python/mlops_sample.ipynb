{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# For hiding passwords\n",
    "import getpass\n",
    "\n",
    "# For working with data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# For building models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ignoring user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', message='Unverified HTTPS request')\n",
    "\n",
    "# For registering models\n",
    "from sasctl import publish_model, pzmm, Session\n",
    "from pathlib import Path\n",
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"./data/Detailed_Statistics_Arrivals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee989d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap Airline Names\n",
    "dict = {\"AA\" : 'American Airlines', \n",
    "        \"AS\" : 'Alaska Airlines', \n",
    "        \"B6\": 'JetBlue Airways', \n",
    "        \"DL\" : 'Delta Airlines', \n",
    "        \"F9\": 'Frontier Airlines',\n",
    "        \"NK\": 'Spirit Airlines',\n",
    "        \"WN\": 'Southwest Airlines'}\n",
    "\n",
    "data = data.replace({\"Carrier\": dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aecb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up date columns\n",
    "data['DayofMonth'] = pd.to_datetime(data['Date'], format='%m/%d/%Y').dt.day\n",
    "data['ScheduledArrivalDatetime'] = pd.to_datetime((data['Date']) + data['ScheduledArrival'], format='%m/%d/%Y%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Delay\n",
    "data['Delay'] = np.where(data['ArrivalDelay'] > 15, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Departure Time\n",
    "data['DepartureDatetime'] = data['ScheduledArrivalDatetime'] - pd.to_timedelta(data['ScheduledElapsedTime'], unit='minute')\n",
    "\n",
    "# Extract Arrival and Departure Hour\n",
    "data['ArrivalHour'] = pd.to_datetime(data['ScheduledArrivalDatetime']).dt.hour\n",
    "data['DepartureHour'] = pd.to_datetime(data['DepartureDatetime']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19249d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up time columns\n",
    "data = data.replace({'24:00': '23:59'})\n",
    "data['ScheduledArrival'] = pd.to_datetime(data['ScheduledArrival'], format='%H:%M').dt.time\n",
    "data['ActualArrival'] = pd.to_datetime(data['ActualArrival'], format='%H:%M').dt.time\n",
    "data['DepartureTime'] = pd.to_datetime(data['DepartureDatetime'], format='%H:%M').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db660ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c43266",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OriginAirport'].value_counts()[:20].plot(kind='bar', xlabel='OriginAirport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae91a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", data['OriginAirport'].nunique(), \"unique origin airports in this dataset.\")\n",
    "\n",
    "print(\"There were\", data[data['OriginAirport'] == 'RDU'].shape[0], \"direct flights from RDU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153528ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data['Carrier'].value_counts(), data.groupby('Carrier')['Delay'].sum()], axis=1).plot.bar(xlabel='Carrier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(data['Delay'].sum() / len(data)* 100, 2), \"% of flights were delayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify inputs and target\n",
    "inputs = ['Carrier', 'DayofMonth', 'OriginAirport', 'ScheduledElapsedTime', 'ArrivalHour', 'DepartureHour']\n",
    "target = 'Delay'\n",
    "\n",
    "# Create X and y datasets\n",
    "X = data[inputs]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8da5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cdec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot-encoding step\n",
    "cat_cols = ['Carrier', 'OriginAirport']\n",
    "cat_onehot_step = ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "cat_pipe = Pipeline([cat_onehot_step])\n",
    "ct = ColumnTransformer(transformers=[('cat', cat_pipe, cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn\n",
    "# Create pipeline with one-hot-encoding and logistic regression\n",
    "logreg_pipe = Pipeline([('transform', ct), ('logreg', LogisticRegression(solver='newton-cg'))])\n",
    "logreg_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd62717",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = logreg_pipe.score(X_train, y_train)\n",
    "test = logreg_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy: \", train)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f78f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "# Create pipeline with one-hot-encoding and xgboost\n",
    "xgb_pipe = Pipeline([('transform', ct), ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))])\n",
    "xgb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a86381",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb_pipe.score(X_train, y_train)\n",
    "test = xgb_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy: \", train)\n",
    "print(\"Test accuracy :\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow\n",
    "\n",
    "forest_pipe = Pipeline([('transform', ct), ('forest', RandomForestClassifier(n_estimators=50, max_depth=7))])\n",
    "forest_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(X_train, forest_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d265bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = forest_pipe.score(X_train, y_train)\n",
    "test = forest_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy: \", train)\n",
    "mlflow.log_metric(\"Training accuracy\", train)\n",
    "print(\"Test accuracy: \", train)\n",
    "mlflow.log_metric(\"Test accuracy\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.log_model(forest_pipe, \"model\", signature=signature)\n",
    "print(\"Model save in run %s\" % mlflow.active_run().info.run_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1db5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "X_train_keras = X_train[['DayofMonth', 'ScheduledElapsedTime', 'ArrivalHour', 'DepartureHour']]\n",
    "X_test_keras = X_test[['DayofMonth', 'ScheduledElapsedTime', 'ArrivalHour', 'DepartureHour']]\n",
    "\n",
    "keras = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(42, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(72, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "keras.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "keras.fit(X_train_keras, y_train)\n",
    "\n",
    "train = keras.evaluate(X_train_keras, y_train)[1]\n",
    "test = keras.evaluate(X_test_keras, y_test)[1]\n",
    "\n",
    "print(\"Training accuracy: \", train)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008a1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Models\n",
    "\n",
    "# The folder where we can store our model files\n",
    "output_folder = 'output'\n",
    "\n",
    "# The model developer, in this case ours truly\n",
    "modeler = \"jpnpul\"\n",
    "\n",
    "# The project within SAS Model Manager\n",
    "project = \"Flight Delay Prediction\"\n",
    "\n",
    "# Model outputs\n",
    "score_metrics = [\"EM_CLASSIFICATION\", \"EM_EVENTPROBABILITY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a952fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sasctl import Session\n",
    "import getpass\n",
    "\n",
    "hostname = getpass.getpass(\"Hostname: \")\n",
    "username = getpass.getpass(\"Username: \")\n",
    "password = getpass.getpass(\"Password: \")\n",
    " \n",
    "sess = Session(hostname, username, password, verify_ssl=False, protocol=\"https\")\n",
    "conn = sess.as_swat()\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5de614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKLearn\n",
    "\n",
    "# STEP 1: Initialize Variables\n",
    "\n",
    "# The trained model\n",
    "model = logreg_pipe\n",
    "\n",
    "# Model name\n",
    "model_prefix = 'SKLearn Logistic Regression v1'\n",
    "\n",
    "# Model algorithm\n",
    "algorithm = 'Logistic Regression'\n",
    "\n",
    "# STEP 2: Create subfolder\n",
    "model_path = Path.cwd() / output_folder / model_prefix\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "# STEP 3: Save binary model representation\n",
    "pzmm.PickleModel.pickle_trained_model(model_prefix=model_prefix, trained_model=model, pickle_path=model_path)\n",
    "\n",
    "# STEP 4: Create metadata files\n",
    "\n",
    "# Model inputs\n",
    "pzmm.JSONFiles.write_var_json(input_data=X, is_input=True, json_path=model_path)\n",
    "\n",
    "# Model outputs\n",
    "output_var = pd.DataFrame(columns=score_metrics, data=[[\"A\", 0.5]])\n",
    "pzmm.JSONFiles.write_var_json(input_data=output_var, is_input=False, json_path=model_path)\n",
    "\n",
    "# Model performance\n",
    "train_data = y_train.to_frame(name='actual').reset_index(drop=True)\n",
    "train_data['probability'] = model.predict_proba(X_train)[:,1]\n",
    "train_data['predict'] = np.where(train_data['probability'] > 0.25, 1, 0)\n",
    "train_data = train_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "test_data = y_test.to_frame(name='actual').reset_index(drop=True)\n",
    "test_data['probability'] = model.predict_proba(X_test)[:,1]\n",
    "test_data['predict'] = np.where(test_data['probability'] > 0.25, 1, 0)\n",
    "test_data = test_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "pzmm.JSONFiles.calculate_model_statistics(target_value=1, prob_value=0.25, \n",
    "                                          train_data=train_data, test_data=test_data, json_path=model_path)\n",
    "\n",
    "# Basic model information\n",
    "pzmm.JSONFiles.write_file_metadata_json(model_prefix=model_prefix, json_path=model_path)\n",
    "\n",
    "pzmm.JSONFiles.write_model_properties_json(model_name=model_prefix, target_variable=target,\n",
    "                                           target_values=['1', '0'], json_path=model_path,\n",
    "                                           model_algorithm=algorithm, modeler=modeler)\n",
    "\n",
    "# Model requirements\n",
    "requirements_json = pzmm.JSONFiles.create_requirements_json(model_path)\n",
    "with open(Path(model_path) / 'requirements.json', 'w') as req_file:\n",
    "    req_file.write(json.dumps(requirements_json, indent=4))\n",
    "    \n",
    "# STEP 5: Import model\n",
    "pzmm.ScoreCode.score_code = ''\n",
    "lreg = pzmm.ImportModel.import_model(model_files=model_path, model_prefix=model_prefix, project=project,\n",
    "                                     input_data=X, predict_method=[model.predict_proba, [float, float]],\n",
    "                                     score_metrics=score_metrics, overwrite_model=True,\n",
    "                                     target_values=['0', '1'], model_file_name=model_prefix + \".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "# STEP 1: Initialize Variables\n",
    "\n",
    "# The trained model\n",
    "model = xgb_pipe\n",
    "\n",
    "# Model name\n",
    "model_prefix = 'XGBoost v1'\n",
    "\n",
    "# Model algorithm\n",
    "algorithm = 'XGBoost'\n",
    "\n",
    "# STEP 2: Create subfolder\n",
    "model_path = Path.cwd() / output_folder / model_prefix\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "# STEP 3: Save binary model representation\n",
    "pzmm.PickleModel.pickle_trained_model(model_prefix=model_prefix, trained_model=model, pickle_path=model_path)\n",
    "\n",
    "# STEP 4: Create metadata files\n",
    "\n",
    "# Model inputs\n",
    "pzmm.JSONFiles.write_var_json(input_data=X, is_input=True, json_path=model_path)\n",
    "\n",
    "# Model outputs\n",
    "output_var = pd.DataFrame(columns=score_metrics, data=[[\"A\", 0.5]])\n",
    "pzmm.JSONFiles.write_var_json(input_data=output_var, is_input=False, json_path=model_path)\n",
    "\n",
    "# Model performance\n",
    "train_data = y_train.to_frame(name='actual').reset_index(drop=True)\n",
    "train_data['probability'] = model.predict_proba(X_train)[:,1]\n",
    "train_data['predict'] = np.where(train_data['probability'] > 0.25, 1, 0)\n",
    "train_data = train_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "test_data = y_test.to_frame(name='actual').reset_index(drop=True)\n",
    "test_data['probability'] = model.predict_proba(X_test)[:,1]\n",
    "test_data['predict'] = np.where(test_data['probability'] > 0.25, 1, 0)\n",
    "test_data = test_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "pzmm.JSONFiles.calculate_model_statistics(target_value=1, prob_value=0.25, \n",
    "                                          train_data=train_data, test_data=test_data, json_path=model_path)\n",
    "\n",
    "# Basic model information\n",
    "pzmm.JSONFiles.write_file_metadata_json(model_prefix=model_prefix, json_path=model_path)\n",
    "\n",
    "pzmm.JSONFiles.write_model_properties_json(model_name=model_prefix, target_variable=target,\n",
    "                                           target_values=['1', '0'], json_path=model_path,\n",
    "                                           model_algorithm=algorithm, modeler=modeler)\n",
    "\n",
    "# Model requirements\n",
    "requirements_json = pzmm.JSONFiles.create_requirements_json(model_path)\n",
    "with open(Path(model_path) / 'requirements.json', 'w') as req_file:\n",
    "    req_file.write(json.dumps(requirements_json, indent=4))\n",
    "    \n",
    "# STEP 5: Import model\n",
    "pzmm.ScoreCode.score_code = ''\n",
    "lreg = pzmm.ImportModel.import_model(model_files=model_path, model_prefix=model_prefix, project=project,\n",
    "                                     input_data=X, predict_method=[model.predict_proba, [float, float]],\n",
    "                                     score_metrics=score_metrics, overwrite_model=True,\n",
    "                                     target_values=['0', '1'], model_file_name=model_prefix + \".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ca713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFlow\n",
    "\n",
    "# STEP 1: Initialize Variables\n",
    "\n",
    "# The trained model\n",
    "model = forest_pipe\n",
    "\n",
    "# Model name\n",
    "model_prefix = 'MLflow Forest v1'\n",
    "\n",
    "# Model algorithm\n",
    "algorithm = 'Random Forest'\n",
    "\n",
    "# Model location\n",
    "mlflow_model_path = Path(\"./mlruns/0/\" + mlflow.active_run().info.run_uuid + \"/artifacts/model\")\n",
    "\n",
    "# MLflow model files\n",
    "metadata_dict, inputs_dict, outputs_dict = pzmm.MLFlowModel.read_mlflow_model_file(mlflow_model_path)\n",
    "\n",
    "\n",
    "# STEP 2: Create subfolder\n",
    "model_path = Path.cwd() / output_folder / model_prefix\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "# STEP 3: Save binary model representation\n",
    "pzmm.PickleModel.pickle_trained_model(model_prefix=model_prefix, pickle_path=model_path, mlflow_details=metadata_dict)\n",
    "\n",
    "# STEP 4: Create metadata files\n",
    "\n",
    "# Model inputs\n",
    "pzmm.JSONFiles.write_var_json(input_data=X, is_input=True, json_path=model_path)\n",
    "\n",
    "# Model outputs\n",
    "output_var = pd.DataFrame(columns=score_metrics, data=[[\"A\", 0.5]])\n",
    "pzmm.JSONFiles.write_var_json(input_data=output_var, is_input=False, json_path=model_path)\n",
    "\n",
    "# Model performance\n",
    "train_data = y_train.to_frame(name='actual').reset_index(drop=True)\n",
    "train_data['probability'] = model.predict_proba(X_train)[:,1]\n",
    "train_data['predict'] = np.where(train_data['probability'] > 0.25, 1, 0)\n",
    "train_data = train_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "test_data = y_test.to_frame(name='actual').reset_index(drop=True)\n",
    "test_data['probability'] = model.predict_proba(X_test)[:,1]\n",
    "test_data['predict'] = np.where(test_data['probability'] > 0.25, 1, 0)\n",
    "test_data = test_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "pzmm.JSONFiles.calculate_model_statistics(target_value=1, prob_value=0.25, \n",
    "                                          train_data=train_data, test_data=test_data, json_path=model_path)\n",
    "\n",
    "# Basic model information\n",
    "pzmm.JSONFiles.write_file_metadata_json(model_prefix=model_prefix, json_path=model_path)\n",
    "\n",
    "pzmm.JSONFiles.write_model_properties_json(model_name=model_prefix, target_variable=\"tensor\",\n",
    "                                           target_values=['1', '0'], json_path=model_path,\n",
    "                                           model_algorithm=algorithm, modeler=modeler)\n",
    "\n",
    "# Model requirements\n",
    "requirements_json = pzmm.JSONFiles.create_requirements_json(model_path)\n",
    "with open(Path(model_path) / 'requirements.json', 'w') as req_file:\n",
    "    req_file.write(json.dumps(requirements_json, indent=4))\n",
    "    \n",
    "# STEP 5: Import model\n",
    "pzmm.ScoreCode.score_code = ''\n",
    "lreg = pzmm.ImportModel.import_model(model_files=model_path, model_prefix=model_prefix, project=project,\n",
    "                                     input_data=X, predict_method=[model.predict_proba, [float, float]],\n",
    "                                     score_metrics=[\"tensor\"], overwrite_model=True,\n",
    "                                     target_values=['0', '1'], pickle_type=metadata_dict[\"serialization_format\"],\n",
    "                                     model_file_name=model_prefix + \".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d87758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "\n",
    "# STEP 1: Initialize Variables\n",
    "\n",
    "# The trained model\n",
    "model = keras\n",
    "\n",
    "# Model name\n",
    "model_prefix = 'Keras Neural Network v1'\n",
    "\n",
    "# Model algorithm\n",
    "algorithm = 'Neural Network'\n",
    "\n",
    "# STEP 2: Create subfolder\n",
    "model_path = Path.cwd() / output_folder / model_prefix\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "# STEP 3: Save binary model representation\n",
    "model.save(output_folder + '/' + model_prefix + '/tfmodel.h5')\n",
    "\n",
    "# STEP 4: Create metadata files\n",
    "\n",
    "# Model inputs\n",
    "pzmm.JSONFiles.write_var_json(input_data=X, is_input=True, json_path=model_path)\n",
    "\n",
    "# Model outputs\n",
    "output_var = pd.DataFrame(columns=score_metrics, data=[[\"A\", 0.5]])\n",
    "pzmm.JSONFiles.write_var_json(input_data=output_var, is_input=False, json_path=model_path)\n",
    "\n",
    "# Model performance\n",
    "train_data = y_train.to_frame(name='actual').reset_index(drop=True)\n",
    "train_data['probability'] = model.predict(X_train_keras)\n",
    "train_data['predict'] = np.where(train_data['probability'] > 0.25, 1, 0)\n",
    "train_data = train_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "test_data = y_test.to_frame(name='actual').reset_index(drop=True)\n",
    "test_data['probability'] = model.predict(X_test_keras)\n",
    "test_data['predict'] = np.where(test_data['probability'] > 0.25, 1, 0)\n",
    "test_data = test_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "pzmm.JSONFiles.calculate_model_statistics(target_value=1, prob_value=0.25, \n",
    "                                          train_data=train_data, test_data=test_data, json_path=model_path)\n",
    "\n",
    "# Basic model information\n",
    "pzmm.JSONFiles.write_file_metadata_json(model_prefix=model_prefix, json_path=model_path)\n",
    "\n",
    "pzmm.JSONFiles.write_model_properties_json(model_name=model_prefix, target_variable=target,\n",
    "                                           target_values=['1', '0'], json_path=model_path,\n",
    "                                           model_algorithm=algorithm, modeler=modeler)\n",
    "\n",
    "# Model requirements\n",
    "requirements_json = pzmm.JSONFiles.create_requirements_json(model_path)\n",
    "with open(Path(model_path) / 'requirements.json', 'w') as req_file:\n",
    "    req_file.write(json.dumps(requirements_json, indent=4))\n",
    "    \n",
    "# STEP 5: Import model\n",
    "pzmm.ScoreCode.score_code = ''\n",
    "lreg = pzmm.ImportModel.import_model(model_files=model_path, model_prefix=model_prefix, project=project,\n",
    "                                     input_data=X_train_keras, predict_method=[model.predict, [int, int]],\n",
    "                                     score_metrics=score_metrics, overwrite_model=True,\n",
    "                                     target_values=['0', '1'], model_file_name=model_prefix + \".h5\",\n",
    "                                     tf_keras_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fc7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
