{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# For hiding passwords\n",
    "import getpass\n",
    "\n",
    "# For working with data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# For building models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Ignoring user warning\n",
    "import warnings\n",
    "# warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "# warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For registering models\n",
    "from sasctl import publish_model, pzmm, Session\n",
    "from pathlib import Path\n",
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"./data/Detailed_Statistics_Arrivals_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987dc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984058a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify inputs and target\n",
    "inputs = ['Carrier', 'DayofMonth', 'OriginAirport', 'ScheduledElapsedTime', 'ArrivalHour', 'DepartureHour']\n",
    "target = 'Delay'\n",
    "\n",
    "# Create X and y datasets\n",
    "X = data[inputs]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45509fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot-encoding step\n",
    "cat_cols = ['Carrier', 'OriginAirport']\n",
    "cat_onehot_step = ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "cat_pipe = Pipeline([cat_onehot_step])\n",
    "ct = ColumnTransformer(transformers=[('cat', cat_pipe, cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e519974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn\n",
    "# Create pipeline with one-hot-encoding and logistic regression\n",
    "logreg_pipe = Pipeline([('transform', ct), ('logreg', LogisticRegression(solver='newton-cg'))])\n",
    "logreg_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = logreg_pipe.score(X_train, y_train)\n",
    "test = logreg_pipe.score(X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy: \", train)\n",
    "print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b97bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Models\n",
    "\n",
    "# The folder where we can store our model files\n",
    "output_folder = 'output'\n",
    "\n",
    "# The model developer, in this case ours truly\n",
    "modeler = \"jpnpul\"\n",
    "\n",
    "# The project within SAS Model Manager\n",
    "project = \"Flight Delay Prediction\"\n",
    "\n",
    "# Model outputs\n",
    "score_metrics = [\"EM_CLASSIFICATION\", \"EM_EVENTPROBABILITY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sasctl import Session\n",
    "import getpass\n",
    "\n",
    "hostname = input(\"Hostname: \")\n",
    "username = input(\"Username: \")\n",
    "password = getpass.getpass(\"Password: \")\n",
    " \n",
    "sess = Session(hostname, username, password, verify_ssl=False, protocol=\"https\")\n",
    "conn = sess.as_swat()\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdcea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKLearn\n",
    "\n",
    "# STEP 1: Initialize Variables\n",
    "\n",
    "# The trained model\n",
    "model = logreg_pipe\n",
    "\n",
    "# Model name\n",
    "model_prefix = 'SKLearn Logistic Regression v1'\n",
    "\n",
    "# Model algorithm\n",
    "algorithm = 'Logistic Regression'\n",
    "\n",
    "# STEP 2: Create subfolder\n",
    "model_path = Path.cwd() / output_folder / model_prefix\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "# STEP 3: Save binary model representation\n",
    "pzmm.PickleModel.pickle_trained_model(model_prefix=model_prefix, trained_model=model, pickle_path=model_path)\n",
    "\n",
    "# STEP 4: Create metadata files\n",
    "\n",
    "# Model inputs\n",
    "pzmm.JSONFiles.write_var_json(input_data=X, is_input=True, json_path=model_path)\n",
    "\n",
    "# Model outputs\n",
    "output_var = pd.DataFrame(columns=score_metrics, data=[[\"A\", 0.5]])\n",
    "pzmm.JSONFiles.write_var_json(input_data=output_var, is_input=False, json_path=model_path)\n",
    "\n",
    "# Model performance\n",
    "train_data = y_train.to_frame(name='actual').reset_index(drop=True)\n",
    "train_data['probability'] = model.predict_proba(X_train)[:,1]\n",
    "train_data['predict'] = np.where(train_data['probability'] > 0.25, 1, 0)\n",
    "train_data = train_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "test_data = y_test.to_frame(name='actual').reset_index(drop=True)\n",
    "test_data['probability'] = model.predict_proba(X_test)[:,1]\n",
    "test_data['predict'] = np.where(test_data['probability'] > 0.25, 1, 0)\n",
    "test_data = test_data[['actual', 'predict', 'probability']]\n",
    "\n",
    "pzmm.JSONFiles.calculate_model_statistics(target_value=1, prob_value=0.25, \n",
    "                                          train_data=train_data, test_data=test_data, json_path=model_path)\n",
    "\n",
    "# Basic model information\n",
    "pzmm.JSONFiles.write_file_metadata_json(model_prefix=model_prefix, json_path=model_path)\n",
    "\n",
    "pzmm.JSONFiles.write_model_properties_json(model_name=model_prefix, target_variable=target,\n",
    "                                           target_values=['1', '0'], json_path=model_path,\n",
    "                                           model_algorithm=algorithm, modeler=modeler)\n",
    "\n",
    "# Model requirements\n",
    "requirements_json = pzmm.JSONFiles.create_requirements_json(model_path)\n",
    "with open(Path(model_path) / 'requirements.json', 'w') as req_file:\n",
    "    req_file.write(json.dumps(requirements_json, indent=4))\n",
    "    \n",
    "# STEP 5: Import model\n",
    "pzmm.ScoreCode.score_code = ''\n",
    "lreg = pzmm.ImportModel.import_model(model_files=model_path, model_prefix=model_prefix, project=project,\n",
    "                                     input_data=X, predict_method=[model.predict_proba, [float, float]],\n",
    "                                     score_metrics=score_metrics, overwrite_model=True,\n",
    "                                     target_values=['0', '1'], model_file_name=model_prefix + \".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0191f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
