{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df45f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import requests\n",
    "import json\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pathlib import Path\n",
    "# sasctl interface for importing models\n",
    "import sasctl.pzmm as pzmm \n",
    "from sasctl import Session\n",
    "import warnings\n",
    "import getpass\n",
    "from sasctl import Session\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81264e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load dataset \n",
    "## split data to train and test \n",
    "digits = datasets.load_digits() #dataset loading\n",
    "x = digits.data               #Features stored in X \n",
    "y = digits.target \n",
    "\n",
    "df = pd.DataFrame(data= np.c_[digits['data'], digits['target']],\n",
    "                     columns= digits['feature_names'] + ['target'])\n",
    "df.head()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[digits['feature_names']], df['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29902509",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Launch mflow from command line\n",
    "## mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f728e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/code/sascode/python/mlruns/1', creation_time=1695264776384, experiment_id='1', last_update_time=1695264776384, lifecycle_stage='active', name='digits-classification', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## setup mlflow experiment\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\") #  connects to a tracking URI.\n",
    "mlflow.set_experiment(\"digits-classification\") ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cda6798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.975\n",
      "Model saved in run 0e6e4a52836848cf8ab2d471a79186a0\n"
     ]
    }
   ],
   "source": [
    "## define randomforest model \n",
    "model = RandomForestClassifier(n_estimators=300, max_depth=20).fit(x_train, y_train)\n",
    "\n",
    "##Model signature defines schema of model input and output\n",
    "signature = infer_signature(x_train, model.predict(x_train))\n",
    "\n",
    "## log model score to mlflow\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"Score: %s\" % score)\n",
    "mlflow.log_metric(\"score\", score)\n",
    "\n",
    "### log model \n",
    "mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5320adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlPath = Path(f'./mlruns/1/{mlflow.active_run().info.run_uuid}/artifacts/model')\n",
    "\n",
    "## get info aboud model variables ,input and output\n",
    "varDict, inputsDict, outputsDict = pzmm.MLFlowModel.read_mlflow_model_file(mlPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug method by jpnpul\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class DebugMLFlowModel:\n",
    "    @classmethod\n",
    "    def read_mlflow_model_file(cls, m_path=Path.cwd()):\n",
    "        \"\"\"\n",
    "        Read and return model metadata and input/output variables as dictionaries from\n",
    "        an MLFlow model directory.\n",
    "\n",
    "        Current implementation only handles simple pickled models. Future feature work\n",
    "        is required to include more types of MLFlow models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        m_path : str or Path object, optional\n",
    "        Directory path of the MLFlow model files. Default is the current working\n",
    "        directory.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        var_dict : dict\n",
    "            Model properties and metadata\n",
    "        inputs_dict : list of dicts\n",
    "            Model input variables\n",
    "        outputs_dict : list of dicts\n",
    "            Model output variables\n",
    "        \"\"\"\n",
    "        with open(Path(m_path) / \"MLmodel\", \"r\") as m_file:\n",
    "            m_lines = m_file.readlines()\n",
    "\n",
    "        # Read in metadata and properties from the MLFlow model\n",
    "        var_list = [\"python_version\", \"serialization_format\", \"run_id\", \"model_path\"]\n",
    "        for i, var_string in enumerate(var_list):\n",
    "            index = [i for i, s in enumerate(m_lines) if var_string in s]\n",
    "            if not index:\n",
    "                raise ValueError(\"This MLFlow model type is not currently supported.\")\n",
    "            var_list[i] = {var_list[i]: m_lines[index[0]].strip().split(\" \")[1]}\n",
    "\n",
    "        var_dict = {k: v for d in var_list for k, v in d.items()}\n",
    "        var_dict[\"mlflowPath\"] = m_path\n",
    "\n",
    "        # Read in the input and output variables\n",
    "        ind_in = [i for i, s in enumerate(m_lines) if \"inputs:\" in s]\n",
    "        ind_out = [i for i, s in enumerate(m_lines) if \"outputs:\" in s]\n",
    "        \n",
    "#        print(m_lines)\n",
    "#         print(ind_in)\n",
    "#         print(ind_out)\n",
    "        \n",
    "        if ind_in and ind_out:\n",
    "            inputs = m_lines[ind_in[0] : ind_out[0]]\n",
    "            outputs = m_lines[ind_out[0] : -1]\n",
    "\n",
    "#             print(inputs)\n",
    "            print(outputs)\n",
    "            \n",
    "            inputs_dict = json.loads(\"\".join([s.strip() for s in inputs])[9:-1])\n",
    "            outputs_dict = json.loads(\"\".join([s.strip() for s in outputs])[10:-1])\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Improper or unset signature values for model. No input or output \"\n",
    "                \"dicts could be generated. \"\n",
    "            )\n",
    "        return var_dict, inputs_dict, outputs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02785c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "varDict, inputsDict, outputsDict = DebugMLFlowModel.read_mlflow_model_file(mlPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f61e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a40e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
